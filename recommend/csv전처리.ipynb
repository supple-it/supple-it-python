{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì „ì²´ ë°ì´í„°ì˜ ê¸°ëŠ¥ì„±í•­ëª©ì— í•´ë‹¹ í‚¤ì›Œë“œë¥¼ í¬í•¨í•œ ì œí’ˆì„ ì¶”ì¶œ (ver.1)\n",
    "#### ì•„ë˜ì˜ ver.2ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/supplements_20250311.csv')\n",
    "# í‚¤ì›Œë“œ ëª©ë¡ (ì‚¬ìš©ìê°€ ì°¾ì„ ê°€ëŠ¥ì„±ì´ ë†’ì€ ì£¼ìš” ê¸°ëŠ¥ì„±)\n",
    "keywords = ['ë¹„íƒ€ë¯¼']\n",
    "\n",
    "# í‚¤ì›Œë“œë³„ë¡œ ì œí’ˆì„ í•„í„°ë§ í›„ CSVë¡œ ì €ì¥\n",
    "for keyword in keywords:\n",
    "    filtered_df = df[df['ê¸°ëŠ¥ì„±'].str.contains(keyword, case=False, na=False)]\n",
    "    \n",
    "    if not filtered_df.empty:\n",
    "        file_name = f'preprocessed_{keyword.replace(\" \", \"_\")}.csv'\n",
    "        filtered_df.to_csv(file_name, index=False, encoding='utf-8-sig')\n",
    "        print(f\"ğŸ“‚ '{keyword}' ê´€ë ¨ ì œí’ˆì„ '{file_name}'ë¡œ ì €ì¥ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì „ì²´ ë°ì´í„°ì˜ ê¸°ëŠ¥ì„±í•­ëª©ì— í•´ë‹¹ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ê³  êµ­ë‚´ì—ì„œ íŒë§¤í•˜ì§€ ì•ŠëŠ” ì œí’ˆì„ í•„í„°ë§.(ver.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ì˜ì–‘ì œ ì„±ë¶„ (Top 10) \n",
    "ë¹„íƒ€ë¯¼\t4678.35   \n",
    "ë‹¨ë°±ì§ˆ\t2200.61   \n",
    "ì¹¼ìŠ˜\t2130.34   \n",
    "ì‹œìŠ¤í…Œì¸\t1521.23   \n",
    "ì•„ì—°\t1455.68   \n",
    "í”„ë¡œë°”ì´ì˜¤í‹±ìŠ¤\t1431.49   \n",
    "í™ì‚¼\t784.47    \n",
    "ì—½ì‚°\t909.28    \n",
    "ì…€ë Œ\t597.90    \n",
    "ë‚˜ì´ì•„ì‹ \t562.80    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ë¹„íƒ€ë¯¼' ê´€ë ¨ ì œí’ˆì„ './data/nutrient\\preprocessed_ë¹„íƒ€ë¯¼.csv'ë¡œ ì €ì¥ ì™„ë£Œ!\n",
      "'ë‹¨ë°±ì§ˆ' ê´€ë ¨ ì œí’ˆì„ './data/nutrient\\preprocessed_ë‹¨ë°±ì§ˆ.csv'ë¡œ ì €ì¥ ì™„ë£Œ!\n",
      "'ì¹¼ìŠ˜' ê´€ë ¨ ì œí’ˆì„ './data/nutrient\\preprocessed_ì¹¼ìŠ˜.csv'ë¡œ ì €ì¥ ì™„ë£Œ!\n",
      "'ì•„ì—°' ê´€ë ¨ ì œí’ˆì„ './data/nutrient\\preprocessed_ì•„ì—°.csv'ë¡œ ì €ì¥ ì™„ë£Œ!\n",
      "'í”„ë¡œë°”ì´ì˜¤í‹±ìŠ¤' ê´€ë ¨ ì œí’ˆì„ './data/nutrient\\preprocessed_í”„ë¡œë°”ì´ì˜¤í‹±ìŠ¤.csv'ë¡œ ì €ì¥ ì™„ë£Œ!\n",
      "'ì‹œìŠ¤í…Œì¸' ê´€ë ¨ ì œí’ˆì„ './data/nutrient\\preprocessed_ì‹œìŠ¤í…Œì¸.csv'ë¡œ ì €ì¥ ì™„ë£Œ!\n",
      "'ì—½ì‚°' ê´€ë ¨ ì œí’ˆì„ './data/nutrient\\preprocessed_ì—½ì‚°.csv'ë¡œ ì €ì¥ ì™„ë£Œ!\n",
      "'ì…€ë Œ' ê´€ë ¨ ì œí’ˆì„ './data/nutrient\\preprocessed_ì…€ë Œ.csv'ë¡œ ì €ì¥ ì™„ë£Œ!\n",
      "'ë‚˜ì´ì•„ì‹ ' ê´€ë ¨ ì œí’ˆì„ './data/nutrient\\preprocessed_ë‚˜ì´ì•„ì‹ .csv'ë¡œ ì €ì¥ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ì˜ì–‘ì†Œë³„ ì „ì²˜ë¦¬\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# CSV íŒŒì¼ ë¡œë“œ\n",
    "df = pd.read_csv('./data/supplements_20250311.csv')\n",
    "\n",
    "# ê²€ìƒ‰í•  ì˜ì–‘ì†Œ ë¦¬ìŠ¤íŠ¸\n",
    "keywords = ['ë¹„íƒ€ë¯¼', 'ë‹¨ë°±ì§ˆ', 'ì¹¼ìŠ˜', 'ì•„ì—°', 'í”„ë¡œë°”ì´ì˜¤í‹±ìŠ¤', 'ì‹œìŠ¤í…Œì¸','ì—½ì‚°','ì…€ë Œ','ë‚˜ì´ì•„ì‹ ']\n",
    "\n",
    "# ì €ì¥í•  í´ë” ê²½ë¡œ\n",
    "file_path = \"./data/nutrient\"\n",
    "\n",
    "# í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
    "if not os.path.exists(file_path):\n",
    "    os.makedirs(file_path)\n",
    "\n",
    "# ê° ì˜ì–‘ì†Œë³„ë¡œ í•„í„°ë§í•˜ì—¬ CSV ì €ì¥\n",
    "for keyword in keywords:\n",
    "    # \"ê¸°ëŠ¥ì„±\" ì—´ì—ì„œ keywordê°€ í¬í•¨ëœ ë°ì´í„° í•„í„°ë§\n",
    "    filtered_df = df[df['ê¸°ëŠ¥ì„±'].str.contains(keyword, case=False, na=False)]\n",
    "    \n",
    "    # \"ì œí’ˆëª…\" ì—´ì—ì„œ \"ìˆ˜ì¶œ\"ì´ í¬í•¨ëœ í•­ëª© ì œì™¸\n",
    "    filtered_df = filtered_df[~filtered_df['ì œí’ˆëª…'].str.contains('ìˆ˜ì¶œ', case=False, na=False)]\n",
    "    \n",
    "    if not filtered_df.empty:\n",
    "        file_name = f'preprocessed_{keyword.replace(\" \", \"_\")}.csv'\n",
    "        full_path = os.path.join(file_path, file_name)\n",
    "        \n",
    "        # CSV íŒŒì¼ ì €ì¥\n",
    "        filtered_df.to_csv(full_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"'{keyword}' ê´€ë ¨ ì œí’ˆì„ '{full_path}'ë¡œ ì €ì¥ ì™„ë£Œ!\")\n",
    "    else:\n",
    "        print(f\"'{keyword}' ê´€ë ¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¶€ìœ„/ê¸°ëŠ¥ ê´€ë ¨ (Top 10)   \n",
    "í”¼ë¡œ\t2783.03   \n",
    "ê³¨ë‹¤ê³µì¦\t2207.18   \n",
    "ì§€ë°©\t1930.31   \n",
    "í”¼ë¶€\t1520.61     \n",
    "ì²´ì§€ë°©\t1513.37   \n",
    "í˜ˆí–‰\t1239.05   \n",
    "ê·¼ìœ¡\t1162.89   \n",
    "ì‹ ê²½\t1131.90   \n",
    "ì½œë ˆìŠ¤í…Œë¡¤\t1083.12   \n",
    "ê´€ì ˆ\t1075.39     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'í”¼ë¡œ' ê´€ë ¨ ì œí’ˆì„ '../data/efficacy\\preprocessed_í”¼ë¡œ.csv'ë¡œ ì €ì¥ ì™„ë£Œ!\n",
      "'ê³¨ë‹¤ê³µì¦' ê´€ë ¨ ì œí’ˆì„ '../data/efficacy\\preprocessed_ê³¨ë‹¤ê³µì¦.csv'ë¡œ ì €ì¥ ì™„ë£Œ!\n",
      "'í”¼ë¶€' ê´€ë ¨ ì œí’ˆì„ '../data/efficacy\\preprocessed_í”¼ë¶€.csv'ë¡œ ì €ì¥ ì™„ë£Œ!\n",
      "'ì²´ì§€ë°©' ê´€ë ¨ ì œí’ˆì„ '../data/efficacy\\preprocessed_ì²´ì§€ë°©.csv'ë¡œ ì €ì¥ ì™„ë£Œ!\n",
      "'í˜ˆí–‰' ê´€ë ¨ ì œí’ˆì„ '../data/efficacy\\preprocessed_í˜ˆí–‰.csv'ë¡œ ì €ì¥ ì™„ë£Œ!\n",
      "'ê·¼ìœ¡' ê´€ë ¨ ì œí’ˆì„ '../data/efficacy\\preprocessed_ê·¼ìœ¡.csv'ë¡œ ì €ì¥ ì™„ë£Œ!\n",
      "'ì‹ ê²½' ê´€ë ¨ ì œí’ˆì„ '../data/efficacy\\preprocessed_ì‹ ê²½.csv'ë¡œ ì €ì¥ ì™„ë£Œ!\n",
      "'ì½œë ˆìŠ¤í…Œë¡¤' ê´€ë ¨ ì œí’ˆì„ '../data/efficacy\\preprocessed_ì½œë ˆìŠ¤í…Œë¡¤.csv'ë¡œ ì €ì¥ ì™„ë£Œ!\n",
      "'ê´€ì ˆ' ê´€ë ¨ ì œí’ˆì„ '../data/efficacy\\preprocessed_ê´€ì ˆ.csv'ë¡œ ì €ì¥ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# íš¨ëŠ¥ë³„ ì „ì²˜ë¦¬ \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# CSV íŒŒì¼ ë¡œë“œ\n",
    "df = pd.read_csv('../data/supplements_20250311.csv')\n",
    "\n",
    "# ê²€ìƒ‰í•  íš¨ëŠ¥ ë¦¬ìŠ¤íŠ¸\n",
    "keywords = ['í”¼ë¡œ', 'ê³¨ë‹¤ê³µì¦', 'í”¼ë¶€', 'ì²´ì§€ë°©', 'í˜ˆí–‰', 'ê·¼ìœ¡', 'ì‹ ê²½', 'ì½œë ˆìŠ¤í…Œë¡¤', 'ê´€ì ˆ']\n",
    "\n",
    "# ì €ì¥í•  í´ë” ê²½ë¡œ\n",
    "file_path = \"../data/efficacy\"\n",
    "\n",
    "# í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
    "if not os.path.exists(file_path):\n",
    "    os.makedirs(file_path)\n",
    "\n",
    "# ê° ì˜ì–‘ì†Œë³„ë¡œ í•„í„°ë§í•˜ì—¬ CSV ì €ì¥\n",
    "for keyword in keywords:\n",
    "    # \"ê¸°ëŠ¥ì„±\" ì—´ì—ì„œ keywordê°€ í¬í•¨ëœ ë°ì´í„° í•„í„°ë§\n",
    "    filtered_df = df[df['ê¸°ëŠ¥ì„±'].str.contains(keyword, case=False, na=False)]\n",
    "    \n",
    "    # \"ì œí’ˆëª…\" ì—´ì—ì„œ \"ìˆ˜ì¶œ\"ì´ í¬í•¨ëœ í•­ëª© ì œì™¸\n",
    "    filtered_df = filtered_df[~filtered_df['ì œí’ˆëª…'].str.contains('ìˆ˜ì¶œ', case=False, na=False)]\n",
    "    \n",
    "    if not filtered_df.empty:\n",
    "        file_name = f'preprocessed_{keyword.replace(\" \", \"_\")}.csv'\n",
    "        full_path = os.path.join(file_path, file_name)\n",
    "        \n",
    "        # CSV íŒŒì¼ ì €ì¥\n",
    "        filtered_df.to_csv(full_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"'{keyword}' ê´€ë ¨ ì œí’ˆì„ '{full_path}'ë¡œ ì €ì¥ ì™„ë£Œ!\")\n",
    "    else:\n",
    "        print(f\"'{keyword}' ê´€ë ¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SUPPLE IT-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
