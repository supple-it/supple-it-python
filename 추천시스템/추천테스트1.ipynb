{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì‹œë¡œ Jupyter Notebookì—ì„œ í…ŒìŠ¤íŠ¸í•˜ëŠ” ì½”ë“œ\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "df = pd.read_csv('../data/supplements_20250311.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40459 entries, 0 to 40458\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ì œì¡°ì‚¬     40459 non-null  object\n",
      " 1   ì œí’ˆëª…     40459 non-null  object\n",
      " 2   ì‹ ê³ ë²ˆí˜¸    40459 non-null  int64 \n",
      " 3   ë“±ë¡ì¼     40459 non-null  int64 \n",
      " 4   ìœ í†µê¸°í•œ    40457 non-null  object\n",
      " 5   ê¸°ëŠ¥ì„±     40451 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ 'ë¹„íƒ€ë¯¼C' ê´€ë ¨ ì œí’ˆì„ 'preprocessed_ë¹„íƒ€ë¯¼C.csv'ë¡œ ì €ì¥ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# í‚¤ì›Œë“œ ëª©ë¡ (ì‚¬ìš©ìê°€ ì°¾ì„ ê°€ëŠ¥ì„±ì´ ë†’ì€ ì£¼ìš” ê¸°ëŠ¥ì„±)\n",
    "keywords = ['ë¹„íƒ€ë¯¼C']\n",
    "\n",
    "# í‚¤ì›Œë“œë³„ë¡œ ì œí’ˆì„ í•„í„°ë§ í›„ CSVë¡œ ì €ì¥\n",
    "for keyword in keywords:\n",
    "    filtered_df = df[df['ê¸°ëŠ¥ì„±'].str.contains(keyword, case=False, na=False)]\n",
    "    \n",
    "    if not filtered_df.empty:\n",
    "        file_name = f'preprocessed_{keyword.replace(\" \", \"_\")}.csv'\n",
    "        filtered_df.to_csv(file_name, index=False, encoding='utf-8-sig')\n",
    "        print(f\"ğŸ“‚ '{keyword}' ê´€ë ¨ ì œí’ˆì„ '{file_name}'ë¡œ ì €ì¥ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 ì œí’ˆëª…\n",
      "885   ë²¨ë”ì›° ì´ë®¨ ë©€í‹°ë¹„íƒ€ ë“€ì˜¤\n",
      "2144    ì´ë®¨ ë“€ì˜¤ ë©€í‹°ë¹„íƒ€ë§¥ìŠ¤\n",
      "3363       ê°„ì—ì¢‹ì€ ë°€í¬ì”¨ìŠ¬\n",
      "1332     ì†Œì¤‘í•œ ëˆˆê±´ê°• ë£¨í…Œì¸\n",
      "468       ë©€í‹°ë¹„íƒ€ë¯¼ ë©´ì—­ ì—…\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# CSV íŒŒì¼ ë¡œë“œ\n",
    "df = pd.read_csv('preprocessed_ë¹„íƒ€ë¯¼C.csv')\n",
    "\n",
    "# ê²°ì¸¡ê°’ ì œê±°\n",
    "df = df.dropna(subset=['ê¸°ëŠ¥ì„±'])\n",
    "\n",
    "# TF-IDF ë²¡í„°í™”\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(df['ê¸°ëŠ¥ì„±'])\n",
    "\n",
    "# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# **ğŸ“Œ í‚¤ì›Œë“œë¥¼ TF-IDFë¡œ ê²€ìƒ‰í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë³€ê²½**\n",
    "def recommend(keyword, limit=5):\n",
    "    \"\"\"í‚¤ì›Œë“œ ê¸°ë°˜ ì œí’ˆ ì¶”ì²œ\"\"\"\n",
    "    # ğŸ”¹ í‚¤ì›Œë“œë¥¼ TF-IDFë¡œ ë³€í™˜\n",
    "    keyword_vec = tfidf.transform([keyword])\n",
    "\n",
    "    # ğŸ”¹ í‚¤ì›Œë“œì™€ ëª¨ë“  ì œí’ˆ ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "    sim_scores = cosine_similarity(keyword_vec, tfidf_matrix)[0]\n",
    "\n",
    "    # ğŸ”¹ ìœ ì‚¬ë„ê°€ ë†’ì€ ìƒìœ„ limitê°œ ì œí’ˆ ê°€ì ¸ì˜¤ê¸°\n",
    "    top_indices = sim_scores.argsort()[-limit:][::-1]\n",
    "\n",
    "    return df[['ì œí’ˆëª…']].iloc[top_indices]\n",
    "\n",
    "# ì˜ˆì‹œ í…ŒìŠ¤íŠ¸: 'ë¹„íƒ€ë¯¼ C'ì™€ ê´€ë ¨ëœ ì¶”ì²œ ì œí’ˆ\n",
    "recommend_results = recommend('ë¹„íƒ€ë¯¼ C', limit=5)\n",
    "print(recommend_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ 'í”¼ë¡œ' ê´€ë ¨ ì œí’ˆì„ 'preprocessed_í”¼ë¡œ.csv'ë¡œ ì €ì¥ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# í‚¤ì›Œë“œ ëª©ë¡ (ì‚¬ìš©ìê°€ ì°¾ì„ ê°€ëŠ¥ì„±ì´ ë†’ì€ ì£¼ìš” ê¸°ëŠ¥ì„±)\n",
    "keywords = ['í”¼ë¡œ']\n",
    "\n",
    "# í‚¤ì›Œë“œë³„ë¡œ ì œí’ˆì„ í•„í„°ë§ í›„ CSVë¡œ ì €ì¥\n",
    "for keyword in keywords:\n",
    "    filtered_df = df[df['ê¸°ëŠ¥ì„±'].str.contains(keyword, case=False, na=False)]\n",
    "    \n",
    "    if not filtered_df.empty:\n",
    "        file_name = f'preprocessed_{keyword.replace(\" \", \"_\")}.csv'\n",
    "        filtered_df.to_csv(file_name, index=False, encoding='utf-8-sig')\n",
    "        print(f\"ğŸ“‚ '{keyword}' ê´€ë ¨ ì œí’ˆì„ '{file_name}'ë¡œ ì €ì¥ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ì œí’ˆëª…\n",
      "178      ê°„í¸í•œ ë°€í¬ì”¨ìŠ¬\n",
      "125          í‹°ì•Œì—ìŠ¤\n",
      "157       í™ê²½ì²œë¹„íƒ€ë¯¼C\n",
      "184      ê³¨ë“ ë£¨íŠ¸ë°€í¬ì”¨ìŠ¬\n",
      "136  í”¼ë¡œì—” í™ê²½ì²œ ë°€í¬ì”¨ìŠ¬\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# CSV íŒŒì¼ ë¡œë“œ\n",
    "df = pd.read_csv('preprocessed_í”¼ë¡œ.csv')\n",
    "\n",
    "# ê²°ì¸¡ê°’ ì œê±°\n",
    "df = df.dropna(subset=['ê¸°ëŠ¥ì„±'])\n",
    "\n",
    "# TF-IDF ë²¡í„°í™”\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(df['ê¸°ëŠ¥ì„±'])\n",
    "\n",
    "# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# **ğŸ“Œ í‚¤ì›Œë“œë¥¼ TF-IDFë¡œ ê²€ìƒ‰í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë³€ê²½**\n",
    "def recommend(keyword, limit=5):\n",
    "    \"\"\"í‚¤ì›Œë“œ ê¸°ë°˜ ì œí’ˆ ì¶”ì²œ\"\"\"\n",
    "    # ğŸ”¹ í‚¤ì›Œë“œë¥¼ TF-IDFë¡œ ë³€í™˜\n",
    "    keyword_vec = tfidf.transform([keyword])\n",
    "\n",
    "    # ğŸ”¹ í‚¤ì›Œë“œì™€ ëª¨ë“  ì œí’ˆ ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "    sim_scores = cosine_similarity(keyword_vec, tfidf_matrix)[0]\n",
    "\n",
    "    # ğŸ”¹ ìœ ì‚¬ë„ê°€ ë†’ì€ ìƒìœ„ limitê°œ ì œí’ˆ ê°€ì ¸ì˜¤ê¸°\n",
    "    top_indices = sim_scores.argsort()[-limit:][::-1]\n",
    "\n",
    "    return df[['ì œí’ˆëª…']].iloc[top_indices]\n",
    "\n",
    "# ì˜ˆì‹œ í…ŒìŠ¤íŠ¸: 'í”¼ë¡œ'ì™€ ê´€ë ¨ëœ ì¶”ì²œ ì œí’ˆ\n",
    "recommend_results = recommend('í”¼ë¡œ', limit=5)\n",
    "print(recommend_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SUPPLE IT-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
